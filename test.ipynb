{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e751c319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 09:41:41.960 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:41.960 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:41.960 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:41.975 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:41.975 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:41.975 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.605 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\chris.mutuku\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-14 09:41:42.611 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.613 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.613 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.613 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.613 Session state does not function when running a script without `streamlit run`\n",
      "2025-04-14 09:41:42.613 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.637 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.637 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.637 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.648 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.650 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.653 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.653 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.653 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.657 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.666 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.666 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.670 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.672 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 09:41:42.674 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import pickle\n",
    "import chardet  # For file encoding detection\n",
    "\n",
    "# Set page config - MUST be first Streamlit command\n",
    "st.set_page_config(page_title=\"SKANEM FORECASTING\", layout=\"wide\")\n",
    "\n",
    "# --------------------------\n",
    "# App Configuration\n",
    "# --------------------------\n",
    "\n",
    "# Logo and title\n",
    "col1, col2 = st.columns([0.1, 0.9])\n",
    "with col1:\n",
    "    st.image(\"https://via.placeholder.com/44\", width=44)  # Replace with your logo path\n",
    "with col2:\n",
    "    st.title(\"Advanced Supply Chain Forecasting\")\n",
    "\n",
    "# --------------------------\n",
    "# Data Management\n",
    "# --------------------------\n",
    "DATA_DIR = \"forecast_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "def save_material_data(material_name, data):\n",
    "    path = os.path.join(DATA_DIR, f\"{material_name.replace(' ', '_')}.pkl\")\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_material_data(material_name):\n",
    "    path = os.path.join(DATA_DIR, f\"{material_name.replace(' ', '_')}.pkl\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return None\n",
    "\n",
    "def get_saved_materials():\n",
    "    return [f.replace('.pkl', '').replace('_', ' ') for f in os.listdir(DATA_DIR) if f.endswith('.pkl')]\n",
    "\n",
    "def detect_encoding(file):\n",
    "    rawdata = file.read()\n",
    "    result = chardet.detect(rawdata)\n",
    "    file.seek(0)  # Reset file pointer\n",
    "    return result['encoding']\n",
    "\n",
    "# --------------------------\n",
    "# Forecasting Models\n",
    "# --------------------------\n",
    "def calculate_metrics(actual, predicted):\n",
    "    return {\n",
    "        'RMSE': np.sqrt(mean_squared_error(actual, predicted)),\n",
    "        'MAPE': mean_absolute_percentage_error(actual, predicted) * 100,\n",
    "        'R2': r2_score(actual, predicted)\n",
    "    }\n",
    "\n",
    "def generate_forecast(current_balance, avg_consumption, variability, horizon):\n",
    "    np.random.seed(42)\n",
    "    dates = pd.date_range(datetime.now(), periods=horizon)\n",
    "    \n",
    "    deterministic = [max(0, current_balance - (i * avg_consumption)) for i in range(horizon)]\n",
    "    daily_variation = 1 + (np.random.rand(horizon) - 0.5) * (variability/100)\n",
    "    probabilistic = [max(0, current_balance - np.sum(avg_consumption * daily_variation[:i+1])) for i in range(horizon)]\n",
    "    \n",
    "    return dates, deterministic, probabilistic\n",
    "\n",
    "def train_supervised_model(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, X_test, y_test\n",
    "\n",
    "def apply_unsupervised_learning(data, n_clusters=3):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(data)\n",
    "    return clusters, kmeans\n",
    "\n",
    "# --------------------------\n",
    "# SKU Consumption Tracker Model\n",
    "# --------------------------\n",
    "def sku_consumption_tracker():\n",
    "    st.title(\"📊 SKU Consumption Tracker\")\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\n",
    "        \"Upload SKU Sales Data (CSV/Excel)\", \n",
    "        type=['csv', 'xlsx'],\n",
    "        help=\"Upload data with columns: Product Number, ProdDescr, Jan, Feb, Mar, etc.\"\n",
    "    )\n",
    "    \n",
    "    if uploaded_file:\n",
    "        try:\n",
    "            # Detect file type and encoding\n",
    "            if uploaded_file.name.endswith('.csv'):\n",
    "                encoding = detect_encoding(uploaded_file)\n",
    "                sku_data = pd.read_csv(uploaded_file, encoding=encoding)\n",
    "            else:\n",
    "                sku_data = pd.read_excel(uploaded_file)\n",
    "            \n",
    "            # Validate columns\n",
    "            required_months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                             'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "            \n",
    "            if not all(col in sku_data.columns for col in ['Product Number', 'ProdDescr'] + required_months):\n",
    "                st.error(\"Required columns missing. Need: Product Number, ProdDescr, and all month columns\")\n",
    "            else:\n",
    "                st.success(\"Data loaded successfully!\")\n",
    "                st.dataframe(sku_data.head())\n",
    "                \n",
    "                # Melt data for time series analysis\n",
    "                melted_data = pd.melt(\n",
    "                    sku_data, \n",
    "                    id_vars=['Product Number', 'ProdDescr'],\n",
    "                    value_vars=required_months,\n",
    "                    var_name='Month',\n",
    "                    value_name='Sales'\n",
    "                )\n",
    "                \n",
    "                # Convert month names to datetime\n",
    "                month_map = {month: i+1 for i, month in enumerate(required_months)}\n",
    "                melted_data['MonthNum'] = melted_data['Month'].map(month_map)\n",
    "                melted_data['Year'] = 2023  # Assuming current year\n",
    "                melted_data['Date'] = pd.to_datetime(\n",
    "                    melted_data['Year'].astype(str) + '-' + \n",
    "                    melted_data['MonthNum'].astype(str) + '-01'\n",
    "                )\n",
    "                \n",
    "                # Show sales trends\n",
    "                selected_sku = st.selectbox(\n",
    "                    \"Select SKU to analyze\",\n",
    "                    options=sku_data['ProdDescr'].unique()\n",
    "                )\n",
    "                \n",
    "                sku_sales = melted_data[melted_data['ProdDescr'] == selected_sku]\n",
    "                \n",
    "                fig = px.line(\n",
    "                    sku_sales,\n",
    "                    x='Date',\n",
    "                    y='Sales',\n",
    "                    title=f\"Monthly Sales Trend for {selected_sku}\",\n",
    "                    markers=True\n",
    "                )\n",
    "                st.plotly_chart(fig)\n",
    "                \n",
    "                # Forecast future consumption\n",
    "                if st.button(\"Forecast Future Consumption\"):\n",
    "                    with st.spinner(\"Training forecasting model...\"):\n",
    "                        try:\n",
    "                            # Prepare data for forecasting\n",
    "                            X = sku_sales[['MonthNum']]\n",
    "                            y = sku_sales['Sales']\n",
    "                            \n",
    "                            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "                            model.fit(X, y)\n",
    "                            \n",
    "                            # Predict next 6 months\n",
    "                            future_months = pd.DataFrame({\n",
    "                                'MonthNum': range(13, 19),\n",
    "                                'Month': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun'],\n",
    "                                'Year': [2024]*6\n",
    "                            })\n",
    "                            \n",
    "                            future_months['Date'] = pd.to_datetime(\n",
    "                                future_months['Year'].astype(str) + '-' + \n",
    "                                future_months['MonthNum'].astype(str) + '-01'\n",
    "                            )\n",
    "                            future_months['Forecast'] = model.predict(future_months[['MonthNum']])\n",
    "                            \n",
    "                            # Combine actual and forecast\n",
    "                            combined = pd.concat([\n",
    "                                sku_sales[['Date', 'Sales']].rename(columns={'Sales': 'Value'}),\n",
    "                                future_months[['Date', 'Forecast']].rename(columns={'Forecast': 'Value'})\n",
    "                            ])\n",
    "                            combined['Type'] = ['Actual']*len(sku_sales) + ['Forecast']*len(future_months)\n",
    "                            \n",
    "                            # Plot results\n",
    "                            fig_forecast = px.line(\n",
    "                                combined,\n",
    "                                x='Date',\n",
    "                                y='Value',\n",
    "                                color='Type',\n",
    "                                title=f\"Sales Forecast for {selected_sku}\",\n",
    "                                markers=True\n",
    "                            )\n",
    "                            st.plotly_chart(fig_forecast)\n",
    "                            \n",
    "                            st.dataframe(future_months[['Month', 'Year', 'Forecast']])\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            st.error(f\"Error in forecasting: {str(e)}\")\n",
    "                            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error reading file: {str(e)}\")\n",
    "\n",
    "# --------------------------\n",
    "# UI Components\n",
    "# --------------------------\n",
    "# Initialize session states\n",
    "if 'current_stocks' not in st.session_state:\n",
    "    st.session_state.current_stocks = pd.DataFrame()\n",
    "if 'historical_data' not in st.session_state:\n",
    "    st.session_state.historical_data = pd.DataFrame()\n",
    "if 'ml_models' not in st.session_state:\n",
    "    st.session_state.ml_models = {}\n",
    "\n",
    "# Sidebar navigation\n",
    "page = st.sidebar.radio(\"Navigation\", \n",
    "    [\"Dashboard\", \"Monthly View\", \"Model Performance\", \"ML Insights\", \"Advanced Forecasting\", \"SKU Consumption Tracker\"])\n",
    "\n",
    "# Page routing\n",
    "if page == \"Dashboard\":\n",
    "    st.title(\"📊 Dashboard\")\n",
    "    st.write(\"Welcome to the dashboard.\")\n",
    "elif page == \"Monthly View\":\n",
    "    st.title(\"📅 Monthly View\")\n",
    "    st.write(\"Monthly forecasting analysis here.\")\n",
    "elif page == \"Model Performance\":\n",
    "    st.title(\"📈 Model Performance\")\n",
    "    st.write(\"Model metrics and evaluation.\")\n",
    "elif page == \"ML Insights\":\n",
    "    st.title(\"🤖 Machine Learning Insights\")\n",
    "    st.write(\"Results from ML modeling.\")\n",
    "elif page == \"Advanced Forecasting\":\n",
    "    # [Rest of your Advanced Forecasting code here...]\n",
    "    # Make sure to update the file uploader to handle encoding:\n",
    "    with st.sidebar.expander(\"📥 Upload Current Inventory\", expanded=True):\n",
    "        uploaded_stocks = st.file_uploader(\n",
    "            \"Upload current inventory (CSV/Excel)\", \n",
    "            type=['csv', 'xlsx'],\n",
    "            help=\"Upload file with columns: 'Item Description' and 'Quantity In Sqr Meters'\"\n",
    "        )\n",
    "        \n",
    "        if uploaded_stocks is not None:\n",
    "            try:\n",
    "                if uploaded_stocks.name.endswith('.csv'):\n",
    "                    encoding = detect_encoding(uploaded_stocks)\n",
    "                    st.session_state.current_stocks = pd.read_csv(uploaded_stocks, encoding=encoding)\n",
    "                else:\n",
    "                    st.session_state.current_stocks = pd.read_excel(uploaded_stocks)\n",
    "                \n",
    "                st.success(f\"Uploaded {len(st.session_state.current_stocks)} records\")\n",
    "                \n",
    "                # Validate columns\n",
    "                required_cols = {'Item Description', 'Quantity In Sqr Meters'}\n",
    "                if not required_cols.issubset(st.session_state.current_stocks.columns):\n",
    "                    missing = required_cols - set(st.session_state.current_stocks.columns)\n",
    "                    st.error(f\"Missing columns: {', '.join(missing)}\")\n",
    "                else:\n",
    "                    st.dataframe(st.session_state.current_stocks.head(3))\n",
    "            except Exception as e:\n",
    "                st.error(f\"Error reading file: {str(e)}\")\n",
    "    \n",
    "    # [Rest of your Advanced Forecasting implementation...]\n",
    "    \n",
    "elif page == \"SKU Consumption Tracker\":\n",
    "    sku_consumption_tracker()\n",
    "\n",
    "# --------------------------\n",
    "# About Section\n",
    "# --------------------------\n",
    "st.sidebar.divider()\n",
    "with st.sidebar.expander(\"About\"):\n",
    "    st.write(\"\"\"\n",
    "    **SKANEM Supply Chain Forecasting Tool**  \n",
    "    Version 2.1  \n",
    "    Developed for SKANEM AS  By Chris Mukiti\n",
    "    \n",
    "    \n",
    "    Features:  \n",
    "    - Inventory forecasting  \n",
    "    - SKU consumption tracking  \n",
    "    - Machine learning insights  \n",
    "    - Time-series analysis  \n",
    "    \n",
    "    © 2025 SKANEM AS\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
